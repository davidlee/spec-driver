---
description: Backfill stub specifications with intelligent completion
---

## User Input

```text
$ARGUMENTS
```

You **MUST** consider the user input before proceeding (if not empty).

## Overview

Given a spec ID (e.g., `SPEC-123`), backfill an auto-generated stub specification by:
1. Resetting the spec to a clean template state (preserving frontmatter)
2. Intelligently completing sections using contracts, code analysis, and inference
3. Validating the completed spec

This workflow reduces spec completion time from 2+ hours to <10 minutes while maintaining quality.

## When to Use This Command

Use this command when:
- A spec has `status: stub` or is clearly auto-generated (≤30 lines)
- Contracts exist in `specify/{kind}/{spec-id}/contracts/` (generated via `spec-driver sync`)
- You need to complete the spec to make it useful for development/testing

## Workflow

### 1. Identify the Spec

From the user input, extract the spec ID. If not provided, ask:

**Spec ID to backfill**: _[Wait for response like SPEC-123]_

Validate the spec exists:
```bash
uv run spec-driver list specs --filter <spec-id>
```

### 2. Reset Spec to Template

Run the CLI backfill command to replace the stub body with a fresh template:

```bash
uv run spec-driver backfill spec <spec-id>
```

**What this does**:
- Preserves all frontmatter (id, slug, name, status, kind, packages, etc.)
- Replaces body with clean template sections
- Fills in `spec_id`, `name`, `kind` from frontmatter
- Leaves YAML blocks as boilerplate for you to complete

**If the command fails**:
- "Specification not found" → Verify spec ID is correct
- "has been modified" → Spec is not a stub; use `--force` only if user confirms
- Other errors → Report and stop

### 3. Read the Backfilled Spec

Open and read the spec file to understand its structure:

```bash
# Get spec path
spec_path=$(uv run spec-driver list specs --filter <spec-id> --json | jq -r '.specs[0].path')

# Read the spec
cat "$spec_path"
```

Note:
- The frontmatter contains key metadata (id, name, kind, packages, responsibilities)
- The body has template sections waiting to be filled
- YAML blocks are boilerplate placeholders

### 4. Gather Context

Collect information to intelligently complete the spec:

#### A. Load Contracts

Contracts are generated by `spec-driver sync` and contain code structure info:

```bash
# Find contracts directory
contracts_dir="specify/$(uv run spec-driver list specs --filter <spec-id> --json | jq -r '.specs[0].kind')/<spec-id>/contracts"

# List available contracts
ls -la "$contracts_dir"

# Read each contract file
cat "$contracts_dir"/*.md
```

Contracts typically include:
- Function/method signatures
- Docstrings
- Class structures
- Module-level documentation

#### B. Examine Related Code (if needed)

If contracts lack detail or you need behavior insights:

```bash
# Get packages covered by this spec
packages=$(uv run spec-driver list specs --filter <spec-id> --json | jq -r '.specs[0].packages[]')

# Read relevant code files
# Use your Read tool or similar to examine the actual implementation
```

#### C. Check Related Specs

Look for related specs that might inform requirements or architecture:

```bash
# Find specs in same area
uv run spec-driver list specs --json | jq '.specs[] | select(.packages[] | contains("<package-prefix>"))'

# Read a related spec if it helps
cat specify/tech/SPEC-XXX/SPEC-XXX.md
```

### 5. Complete Sections Intelligently

Now fill in the spec sections using the gathered context. Follow the principle:
**Prefer inferring from evidence over asking questions. Make reasonable assumptions and document them.**

#### Section 1: Intent & Summary

- **Scope / Boundaries**: Infer from package names and contracts what's included/excluded
- **Value Signals**: Consider what problem this component solves, metrics from usage
- **Guiding Principles**: Extract from code comments, docstrings, architectural patterns
- **Change History**: Check git history or related deltas if relevant

**Example approach**:
```markdown
## 1. Intent & Summary

- **Scope / Boundaries**:
  - IN: Python module sync adapters for generating contracts from Python code
  - OUT: Non-Python languages, runtime synchronization, bidirectional sync

- **Value Signals**:
  - Enables spec backfill workflow (reduces completion time 2hrs → 10min)
  - 100% coverage of Python codebases after sync

- **Guiding Principles**:
  - Static analysis only (no code execution)
  - Preserve docstring fidelity
  - AST-based extraction for reliability

- **Change History**: Introduced in DE-005 (spec backfill implementation)
```

#### Section 2: Stakeholders & Journeys

For tech specs:
- **Systems / Integrations**: What external systems does this interact with?
- **Primary Journeys / Flows**: Main usage patterns (Given-When-Then)
- **Edge Cases & Non-goals**: What's explicitly out of scope?

**Tip**: Use contracts to identify interfaces and integration points.

#### Section 3: Responsibilities & Requirements

This is the most critical section. Complete in this order:

##### 3.1. Complete YAML Blocks First

**`supekku:spec.relationships@v1`**:
```yaml
```yaml supekku:spec.relationships@v1
schema: supekku.spec.relationships
version: 1
spec: <spec-id>
requirements:
  primary:
    - <spec-id>.FR-001
    - <spec-id>.FR-002
    - <spec-id>.NF-001
  collaborators: []
interactions: []
```
```

**Generate requirements** by analyzing contracts:
- One FR per major function/capability
- NFs for quality attributes (performance, reliability, etc.)
- Follow naming: `<spec-id>.FR-NNN`, `<spec-id>.NF-NNN`

**`supekku:spec.capabilities@v1`**:
```yaml
```yaml supekku:spec.capabilities@v1
schema: supekku.spec.capabilities
version: 1
spec: <spec-id>
capabilities:
  - id: capability-kebab-case
    name: Human Readable Capability Name
    responsibilities:
      - Concrete behavior this capability ensures
    requirements:
      - <spec-id>.FR-001
      - <spec-id>.NF-001
    summary: |
      Short paragraph describing what this capability does and why it matters.
    success_criteria:
      - Measurable indicator of success
      - Another metric or observable outcome
```
```

**`supekku:verification.coverage@v1`**:
```yaml
```yaml supekku:verification.coverage@v1
schema: supekku.verification.coverage
version: 1
subject: <spec-id>
entries:
  - artefact: VT-001
    kind: VT
    requirement: <spec-id>.FR-001
    status: planned
    notes: Description of test artifact
```
```

##### 3.2. Expand in Prose

After YAML blocks, write prose requirements:

**Functional Requirements**:
```markdown
### Functional Requirements

- **<spec-id>.FR-001**: [Component] MUST [specific capability]
  *Example*: Parser MUST extract function signatures from Python AST nodes
  *Verification*: VT-001 - Function signature extraction test

- **<spec-id>.FR-002**: [Component] MUST [behavior or constraint]
  *Example*: Sync adapter MUST preserve docstring formatting (including indentation)
  *Verification*: VT-002 - Docstring preservation test
```

**Non-Functional Requirements**:
```markdown
### Non-Functional Requirements

- **<spec-id>.NF-001**: [Quality attribute] MUST [measurable constraint]
  *Example*: Sync MUST process 1000 Python files in <30 seconds
  *Verification*: VA-001 - Performance benchmark
```

**Inference Guidelines**:
- Infer FRs from function names and docstrings
- Infer NFs from code patterns (caching → performance, error handling → reliability)
- Make reasonable assumptions about implicit requirements
- Document assumptions: "Assuming X based on Y"

#### Section 4: Solution Outline

For tech specs:
- **Architecture**: Component structure, data flow, key abstractions
- **Components**: Main classes/modules and their roles
- **Interfaces**: Public APIs, contracts with other systems
- **Data Models**: Key entities, schemas, state

**Tip**: Use contracts and code structure to describe the architecture.

#### Section 5: Behaviour & Scenarios

- **Primary Flows**: Step-by-step sequences for main use cases
- **Error Handling**: Guards, validation, recovery paths
- **State Transitions**: If stateful, describe state machine

**Example**:
```markdown
## 5. Behaviour & Scenarios

### Primary Flow: Python Module Sync

1. **Given** a Python module path
2. **When** `sync_python_module()` is called
3. **Then** the system:
   - Parses module with AST
   - Extracts functions, classes, methods
   - Generates contract markdown files
   - Writes to `contracts/` directory
```

#### Section 6: Quality & Verification

- **Testing Strategy**: Map requirements to test levels (unit, integration, e2e)
- **Observability**: Metrics, logging, error tracking
- **Security**: Input validation, authentication, authorization
- **Performance**: Targets, benchmarks, optimization strategies

**Keep aligned** with verification YAML block.

#### Section 7: Backlog Hooks & Dependencies

- **Related Specs**: Link to collaborating specs
- **Risks**: Identify and describe mitigation strategies
- **Known Gaps**: Link to backlog items if any
- **Open Decisions**: Questions needing resolution (mark with [NEEDS CLARIFICATION])

### 6. Quality Limits

To maintain workflow efficiency (≤10 min per spec):

**Maximum Clarification Questions**: **3 total**

Only ask when:
- Critical decision significantly impacts design
- Multiple valid interpretations with different trade-offs
- Security/compliance implications
- Scope boundaries unclear from contracts

**For everything else**: Make informed assumptions and document them.

**Assumption Documentation Format**:
```markdown
[ASSUMPTION: Based on contract signatures, assuming synchronous operation.
If async is required, add async/await wrappers in FR-004.]
```

### 7. Validate Completion

Before declaring success, validate the spec:

#### Content Quality Checklist

- [ ] Product specs: No implementation details (languages, frameworks)
- [ ] Tech specs: Implementation details grounded in actual code
- [ ] All YAML blocks valid and parseable
- [ ] Requirements testable and measurable
- [ ] Capabilities link to requirements
- [ ] Verification entries map to actual requirements
- [ ] ≤3 [NEEDS CLARIFICATION] markers
- [ ] Assumptions documented where made

#### Run Validation Commands

```bash
# Sync registry to pick up changes
uv run spec-driver sync

# Validate spec integrity
uv run spec-driver validate

# Check YAML syntax if needed
yq eval '.frontmatter' "$spec_path"
```

**If validation fails**: Fix errors and re-run.

### 8. Document Evidence

Record what you did:

1. **Spec completed**: `<spec-id>` at `<path>`
2. **Contracts used**: List contract files referenced
3. **Assumptions made**: Summarize key assumptions
4. **Clarifications asked**: If any, note what was clarified
5. **Validation status**: Pass/fail with details

**Example**:
```markdown
## Backfill Summary: SPEC-112

**Completed**: 2025-11-02
**Path**: `specify/tech/SPEC-112/SPEC-112.md`
**Contracts Used**:
- `contracts/supekku-cli-schema-all.md`
- `contracts/supekku-cli-schema-public.md`

**Key Inferences**:
- Requirements derived from function signatures in contracts
- Performance target (NF-001) based on typical CLI response times
- Verification strategy aligned with existing test patterns

**Assumptions**:
- Schema validation uses JSON Schema Draft 7 (not specified in contracts)
- CLI errors printed to stderr (standard practice)

**Clarifications**: None (0/3 used)
**Validation**: ✓ Passed `spec-driver sync` and `validate`
```

## Key Commands Reference

```bash
# Reset spec to template
uv run spec-driver backfill spec <spec-id>

# Force if spec has been modified
uv run spec-driver backfill spec <spec-id> --force

# List specs and get details
uv run spec-driver list specs --filter <spec-id>
uv run spec-driver list specs --filter <spec-id> --json

# Show template for reference
uv run spec-driver show template tech
uv run spec-driver show template product

# Sync and validate
uv run spec-driver sync
uv run spec-driver validate

# Get schema documentation
uv run spec-driver schema show spec.relationships
uv run spec-driver schema show spec.capabilities
uv run spec-driver schema show verification.coverage
```

## Execution Principles

### Intelligence Over Questions

- **Prefer**: Inferring from contracts, code, and context
- **Over**: Asking the user for every detail
- **Why**: Reduces friction, maintains workflow speed

### Document Assumptions

When you infer or assume:
- Mark clearly with `[ASSUMPTION: ...]`
- Explain basis for assumption
- Note what would change if assumption is wrong

### Quality Through Evidence

- Ground requirements in actual code/contracts
- Link capabilities to real behaviors
- Verify requirements are testable
- Ensure YAML blocks are valid and complete

### Efficiency Through Scope

- Focus on substance over perfection
- Aim for "good enough to use" not "exhaustively detailed"
- Target: ≤10 minutes per spec
- Defer deep details to implementation phase

## Common Patterns

### When Contracts Are Rich

If contracts have detailed docstrings and signatures:
- Extract FRs directly from function purposes
- Infer NFs from code patterns (error handling, validation, etc.)
- Build capability structure from module organization
- Minimal assumptions needed

### When Contracts Are Sparse

If contracts lack detail:
- Read actual code files for context
- Infer from function names and structure
- Make reasonable assumptions about typical behavior
- Mark sections with [NEEDS CODE REVIEW] if uncertain

### When Packages Are Small

For small, focused specs (1-2 packages):
- Simple capability structure (maybe just 1-2 capabilities)
- Focused requirements (3-5 FRs typical)
- Straightforward architecture
- Quick completion (<5 min)

### When Packages Are Large

For complex specs (many packages):
- Break into multiple capabilities (by concern or layer)
- More requirements (10+ FRs possible)
- Richer architecture section
- May approach 10 min limit

## Final Checklist

Before reporting completion:

- [ ] CLI backfill executed successfully
- [ ] All mandatory sections completed with substance
- [ ] YAML blocks valid (spec.relationships, spec.capabilities, verification.coverage)
- [ ] Requirements numbered sequentially
- [ ] Every requirement has verification approach
- [ ] Capabilities link to requirements
- [ ] ≤3 [NEEDS CLARIFICATION] markers
- [ ] Assumptions documented
- [ ] `uv run spec-driver sync` passed
- [ ] `uv run spec-driver validate` passed
- [ ] Evidence/completion summary documented

## Success Criteria

The spec is ready when:

1. A developer can understand the component without reading code
2. A QA engineer can design test cases from the requirements
3. The spec passes `sync` and `validate` commands
4. All YAML blocks are valid and complete
5. Requirements are testable and traceable
6. Completion time was ≤10 minutes
